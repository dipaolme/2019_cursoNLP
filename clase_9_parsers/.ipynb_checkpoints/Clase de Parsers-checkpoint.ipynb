{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un parser es un algoritmo computacional que **recibe un *input*, lo analiza y lo devuelve ordenado de acuerdo a reglas** que conoce previamente, generalmente en forma de árbol.\n",
    "Tiene cargado un conjunto de reglas que le indican cómo dar formato al *input*. Suele ser parte de un proceso más complejo (lectura de archivos, compilador, etc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizar una cadena de símbolos de acuerdo a una serie de reglas definidas previamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En NLP:**\n",
    "\n",
    "● Recibe información no estructurada: una cadena (*string*) en lenguaje natural \n",
    "\n",
    "● Consta de una gramática que contiene instrucciones de reescritura\n",
    "\n",
    "● Devuelve información estructurada: una representación formal de la estructura sintáctica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un parser, entonces, procesa oraciones de acuerdo a una **gramática**, pero esta no es un programa en sí mismo sino **un conjunto de reglas que le sirven de *input*** para saber cómo analizar las oraciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Para qué?**\n",
    "\n",
    "Una motivación científica para la creación y el uso de los parsers es principalmente el entendimiento. \n",
    "\n",
    "¿Cómo podemos acceder a niveles más profundos del significado a partir del acceso a la estructura sintáctica de una oración. \n",
    "\n",
    "Aunque sepamos la categoría de una palabra, es decir su POS, no tenemos información sobre las relaciones jerárquicas que se establecen entre ellas.\n",
    "\n",
    "El proceso de parsing nos devuelve esa información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El proceso se divide en dos instancias:** \n",
    "    \n",
    "    \n",
    "#### Shallow Parsing: \n",
    " Consiste en \"cortar\" el input en \"pedazos\" y asignarles una etiqueta. El proceso recorre e identifica cada palabra como Vb, N, etc. y luego las agrupa en estructuras mayores (VP, NP, etc). Similar a lo que vimos con POS tagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Parsing: \n",
    "Consiste en producir una representación formal de la estructura sintáctica del input, en general en forma de árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las Gramáticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la primera clase examinamos distintos tipos de lenguajes entendidos como conjuntos de cadenas. Estos lenguajes pueden ser caracterizados por intensión por distintos mecanismos. Uno de estos mecanismos es la elaboración de gramáticas. Además de generar/reconocer/describir lenguajes, las gramáticas poseen la característica adicional de que son capaces de asignar estructura a las cadenas.\n",
    "Existen distintos tipos de gramáticas según el lenguaje que generan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Lenguajes | Gramáticas |\n",
    "| ------ | -----: |\n",
    "| Lenguajes tipo 0 | Gramáticas irrestrictas |\n",
    "| Lenguajes tipo 1 | Gramáticas sensibles al contexto |\n",
    "| Lenguajes tipo 2 | Gramáticas independientes de contexto |\n",
    "| Lenguajes tipo 3 | Gramáticas regulares |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las gramáticas se expresan usualmente en forma de reglas de reescritura de la forma X -> Z (X se reescribe como Z), aunque estas  reglas pueden concebirse también como árboles parcialmente construidos o como restricciones combinatorias. Las gramáticas típicamente permiten construir grafos dirigidos, coloquialmente denominados ''árboles''.\n",
    "Existen tres grandes formas de construir las gramáticas según cómo se conciba la representación de la estructura jerárquica:\n",
    "* Gramáticas basadas en constituyentes\n",
    "* Gramáticas basadas en dependencias\n",
    "* Gramáticas categoriales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gramática basada en constituyentes](constituyentes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gramática de dependencias](dependencias.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gramática categorial](categorial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cómo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo principal es determinar si el string que recibe como imput puede derivarse del símbolo de inicio de la gramática.\n",
    "\n",
    "**Hay dos maneras de hacer esto:**\n",
    "\n",
    "- _bottom-up (Análisis ascendente)_: Parte desde el *input* e intenta llegar a la raíz (O) desde la gramática\n",
    "\n",
    "- _top-down (Análisis descendente)_:  Parte desde la raíz (O) y aplica las reglas para chequear si es capaz de predecir el *input* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gramáticas basadas en constituyentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poseen distinción entre nodos terminales y nodos no terminales, que especifican la categoría a la que pertenece una determinada subcadena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive descent Parser\n",
    "\n",
    "- **Top-down**\n",
    "- Parte del símbolo de inicio y aplica las reglas para obtener los constituyentes inmediatos y armar el árbol hasta llegar a los símbolos terminales. Chequea coincidencia con la secuencia del input. Si no hay coincidencia, tiene que retroceder y buscar diferentes alternativas de parseo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Descent Parser\n",
    "\n",
    "def rd_parser(sentence, grammar):                   # define una función llamada rd_parser con dos argumentos\n",
    "    print(grammar)                                  # imprime mi gramática\n",
    "    sentence = sentence.lower()                     # convierte a minúscula la oración\n",
    "    if sentence.endswith('.'):                      # si la oración termina con un punto\n",
    "        sent = re.sub('\\.',' ',sentence)            # se lo quita\n",
    "    else:                                           # si no\n",
    "        sent = sentence                             # la toma como está\n",
    "    sent = sent.split()                             # divide la oración en palabras\n",
    "    rd_parser = nltk.RecursiveDescentParser(grammar) # proceso esas palabras\n",
    "    for tree in rd_parser.parse(sent):              # para cada árbol posible en mi gramática para esa oración\n",
    "        print(tree)                                 # lo imprimo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escribí una oración:\n",
      "cata fuma\n",
      "Grammar with 40 productions (start state = O)\n",
      "    O -> SN SV\n",
      "    SN -> PRO\n",
      "    SN -> NP\n",
      "    SN -> D NC\n",
      "    NP -> 'martín'\n",
      "    NP -> 'cata'\n",
      "    NP -> 'julia'\n",
      "    NP -> 'fede'\n",
      "    NP -> 'maca'\n",
      "    NP -> 'pablo'\n",
      "    NC -> 'plaza'\n",
      "    NC -> 'facultad'\n",
      "    NC -> 'regalo'\n",
      "    NC -> 'globo'\n",
      "    NC -> 'tabaco'\n",
      "    D -> 'el'\n",
      "    D -> 'la'\n",
      "    D -> 'un'\n",
      "    D -> 'una'\n",
      "    PRO -> 'ella'\n",
      "    PRO -> 'él'\n",
      "    SV -> FV SN SP\n",
      "    SV -> FV SP\n",
      "    SV -> FV\n",
      "    SV -> FV SN\n",
      "    FV -> AUX PART\n",
      "    FV -> V\n",
      "    AUX -> 'fue'\n",
      "    PART -> 'entregado'\n",
      "    PART -> 'enviado'\n",
      "    PART -> 'fumado'\n",
      "    PART -> 'explotado'\n",
      "    V -> 'entregó'\n",
      "    V -> 'envió'\n",
      "    V -> 'explotó'\n",
      "    V -> 'fuma'\n",
      "    SP -> P SN\n",
      "    P -> 'por'\n",
      "    P -> 'en'\n",
      "    P -> 'a'\n",
      "(O (SN (NP cata)) (SV (FV (V fuma))))\n"
     ]
    }
   ],
   "source": [
    "#Para correr el Recursive Descent Parser\n",
    "\n",
    "print('Escribí una oración:')                          #Para que me pida que escriba una oración\n",
    "oracion1 = input()                                     #Para que me abra un campo en el que escriba la oración\n",
    "grammar = nltk.data.load('ContextFreeGrammar.cfg')     # establece cuál va a ser mi gramática\n",
    "rd_parser(oracion1, grammar)                           #Para correr la función"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo del Right Descent Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('under',)]\n",
      "[('with',)]\n",
      "[('in',)]\n",
      "[('under',), ('with',)]\n",
      "[('ate',)]\n",
      "[('saw',)]\n",
      "[('dog',)]\n",
      "[('telescope',)]\n",
      "[('park',)]\n",
      "[('dog',), ('telescope',)]\n",
      "[('man',)]\n",
      "[('park',), ('dog',), ('telescope',)]\n",
      "[('the',)]\n",
      "[('a',)]\n",
      "[(V, NP)]\n",
      "[(V,)]\n",
      "[(V, NP, PP)]\n",
      "[(V, NP), (V,)]\n",
      "[(Det, N, PP)]\n",
      "[(Det, N)]\n",
      "S [(NP, VP)]\n",
      "NP [(Det, N, PP), (Det, N)]\n",
      "VP [(V, NP, PP), (V, NP), (V,)]\n",
      "PP [(P, NP)]\n",
      "NP [('I',)]\n",
      "Det [('the',), ('a',)]\n",
      "N [('man',), ('park',), ('dog',), ('telescope',)]\n",
      "V [('ate',), ('saw',)]\n",
      "P [('in',), ('under',), ('with',)]\n"
     ]
    }
   ],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desventajas:**\n",
    "\n",
    "- La recursividad a la izquierda (NP -> NP PP) lo lleva al loop infinito\n",
    "\n",
    "- Pierde mucho tiempo considerando las estructuras que no se corresponden con el input\n",
    "\n",
    "- En el proceso de backtracking se descartan los parseos anteriores y tiene que volver a construirlos \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bllip Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes hay que instalar el bllip parser. \n",
    "\n",
    "Para hacerlo, correr el siguiente comando en la terminal:\n",
    "\n",
    "    pip install --user bllipparser\n",
    "\n",
    "Brown Laboratory for Linguistic Information Processing\n",
    "\n",
    "Introduce gramáticas a partir de un corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bllipparser import RerankingParser                             #Importa el parser\n",
    "from bllipparser.ModelFetcher import download_and_install_model     # Descarga e instala el \"modelo\"\n",
    "\n",
    "model_dir = download_and_install_model('WSJ', 'tmp/models')         #Crea una variable con el \"modelo\"\n",
    "rrp = RerankingParser.from_unified_model_dir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(S1 (S (NP (NNP jonh)) (VP (VBZ smokes) (NP (DT a) (NN cigarrete)))))'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracion2 = \"jonh smokes a cigarrete\"\n",
    "rrp.simple_parse(oracion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(S1 (S (S (NP (DT No) (NN one)) (VP (VBD saw) (S (NP (PRP him)) (VP (VBP disembark) (PP (IN in) (NP (DT the) (JJ unanimous) (NN night))))))) (, ,) (S (NP (DT no) (NN one)) (VP (VBD saw) (S (NP (DT the) (NN bamboo) (NN canoe)) (VP (VB sink) (PP (IN into) (NP (DT the) (JJ sacred) (NN mud))))))) (, ,) (CC but) (S (PP (IN in) (NP (DT a) (JJ few) (NNS days))) (NP (EX there)) (VP (VBD was) (NP (NP (DT no) (NN one)) (SBAR (WHNP (WP who)) (S (VP (VBD did) (RB not) (VP (VB know) (SBAR (IN that) (S (NP (DT the) (JJ taciturn) (NN man)) (VP (VBD came) (PP (IN from) (NP (DT the) (NNP South)))))))))))))))'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracion3 = \"No one saw him disembark in the unanimous night, no one saw the bamboo canoe sink into the sacred mud, but in a few days there was no one who did not know that the taciturn man came from the South\"\n",
    "rrp.simple_parse(oracion3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escribí una oración en inglés\n",
      "the south is better\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(S1 (S (NP (DT the) (NN south)) (VP (VBZ is) (ADJP (JJR better)))))'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Escribí una oración en inglés')\n",
    "oracion4 = input()\n",
    "rrp.simple_parse(oracion4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gramáticas basadas en dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No poseen distinción entre símbolos no terminales y terminales. Las estructuras representan relaciones de dependencia entre terminales.\n",
    "Ejemplos de parsers de dependencias:\n",
    "* Maltparser (http://www.maltparser.org/)\n",
    "* SyntaxNet (https://opensource.google.com/projects/syntaxnet)\n",
    "* Dependency parser de Spacy (https://spacy.io/usage/linguistic-features#dependency-parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy - Dependency parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "from spacy import displacy \n",
    "\n",
    "def gramaticadependencias(sentence):       #Define la función\n",
    "    nlp = spacy.load('es_core_news_sm')    #Carga el modelo entrenado\n",
    "    doc = nlp(sentence)                    #define una variable doc con la oración procesada por el modelo\n",
    "    #for token in doc:               \n",
    "        #print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "        #    [child for child in token.children])\n",
    "    displacy.render(doc, style='dep', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escribí una oración\n",
      "mi hermano tiene miedo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"750\" height=\"224.5\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">mi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">hermano</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">tiene</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">miedo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,91.5 L237,79.5 253,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Escribí una oración')\n",
    "oracion5 = input()\n",
    "gramaticadependencias(oracion5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gramáticas Categoriales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las gramáticas categoriales están conformadas principalmente por un conjunto reducido de reglas y un léxico sumamente rico.\n",
    "Las reglas que utiliza OpenCCG, que es el parser categorial que vamos a ver son las siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![reglas categoriales](reglascategorialesopenccg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construir una gramática categorial consiste principalmente en elaborar un léxico lo suficientemente rico, ya que las gramáticas categoriales son fuertemente lexicalistas. En ellas, la categoría a la que pertenece cada entrada léxica codifica sus posibilidades combinatorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinatory Categorial Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinatory Categorial Grammar\n",
    "\n",
    "from nltk.ccg import chart, lexicon\n",
    "\n",
    "def combinatory_parser(sentence):   \n",
    "    sentence = sentence.lower()                                     # convierte a minúscula\n",
    "    if sentence.endswith('.'):                                      # si la oración termina con un punto\n",
    "        sent = re.sub('\\.',' ',sentence)                            # se lo quita\n",
    "    else:                                                           # si no\n",
    "        sent = sentence                                             # la toma como está\n",
    "    sent = sent.split()                                             # divide la oración en palabras\n",
    "    archivo = open('CategorialGrammar2.txt', 'r')\n",
    "    codigogram = archivo.read()\n",
    "    lex = lexicon.fromstring(codigogram)\n",
    "    print(lex)\n",
    "    parser = chart.CCGChartParser(lex, chart.DefaultRuleSet)\n",
    "    archivo.close()\n",
    "    for parse in parser.parse(sent):  # doctest: +SKIP\n",
    "         chart.printCCGDerivation(parse)\n",
    "         #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escribí una oración\n",
      "cata fuma\n",
      "a => (PP/NP)\n",
      "cata => NP\n",
      "el => (NP/NC)\n",
      "ella => NP\n",
      "en => (PP/NP)\n",
      "entregado => (PARTP/PP)\n",
      "entregó => (((S\\NP)/NP)/PP)\n",
      "enviado => (PARTP/PP)\n",
      "envió => (((S\\NP)/NP)/PP)\n",
      "explotado => (PARTP/PP)\n",
      "explotó => ((S\\NP)/NP) | (S\\NP)\n",
      "facultad => NC\n",
      "fede => NP\n",
      "fer => NP\n",
      "fue => ((S\\NP)/PARTP)\n",
      "fuma => (S\\NP)\n",
      "fumado => (PARTP/PP)\n",
      "fumó => ((S\\NP)/NP)\n",
      "globo => NC\n",
      "habla => (S\\NP)\n",
      "julia => NP\n",
      "la => (NP/NC)\n",
      "martín => NP\n",
      "pablo => NP\n",
      "plaza => NC\n",
      "por => (PP/NP)\n",
      "regalo => NC\n",
      "tabaco => NC\n",
      "un => (NP/NC)\n",
      "una => (NP/NC)\n",
      "vicky => NP\n",
      "él => NP\n",
      " cata   fuma\n",
      "  NP   (S\\NP)\n",
      "--------------<\n",
      "      S\n"
     ]
    }
   ],
   "source": [
    "print('Escribí una oración')\n",
    "oracion5 = input()\n",
    "combinatory_parser(oracion5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
